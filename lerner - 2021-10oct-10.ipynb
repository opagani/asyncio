{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda -- asyncio\n",
    "\n",
    "1. `asyncio` basics -- what is it?\n",
    "2. Basic use of `asyncio`\n",
    "3. Scheduling and waiting\n",
    "4. Deeper with the event loop\n",
    "5. What if there's no coroutine?  What then?\n",
    "6. Example: HTTP client\n",
    "7. Example: Chatbot\n",
    "8. `asyncio` vs. threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we need asyncio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reactor pattern\n",
    "\n",
    "The problem with current concurrency is:\n",
    "- Threads are lightweight, but hard to work with... and even lightweight threads can overburden a server at a certain point.\n",
    "- Processes are easier to work with, and you can even have a lot of them on a server, but they are very heavyweight, and can bring your server down.\n",
    "\n",
    "The reactor pattern says:\n",
    "- Have one process\n",
    "- Have one thread\n",
    "\n",
    "The idea is: You have a list of functions, and you loop over that list again and again and again. You give each function the chance to execute for a little bit of time.  This way, you can handle a ton of incoming network connections, because the only overhead is additional functions.\n",
    "\n",
    "Each time we get a new network connection, we run a function a new time. If there are *n* incoming connections, then we're running our function *n* times.  Because the overhead of a function is so much lower than threads or processes, we can get away with this.\n",
    "\n",
    "The \"Twisted\" framework in Python has existed for 20+ years, and has used this technique.\n",
    "\n",
    "JavaScript's NodeJS framework for server-side Web apps has been doing this 10-15 years already.\n",
    "\n",
    "`asyncio` is still something of a work in progress.\n",
    "- The API is stable, with fewer changes with each Python version\n",
    "- A growing number of libraries support it\n",
    "- A growing number of people are using it\n",
    "\n",
    "BUT it is still:\n",
    "- Hard to understand\n",
    "- Hard to integrate with much existing software\n",
    "- A lot of the documentation is still unclear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What kinds of problems does `asyncio` solve?\n",
    "\n",
    "Network applications are mostly idle.\n",
    "- When we want to request something from the network (as a client), we wait until we get a response. When we're runn\n",
    "- When we are running a server, much of the time is idle, while the client either sends a request or processes it.\n",
    "\n",
    "There's a ton of idle time there!  That's where `asyncio` comes in.\n",
    "\n",
    "`asyncio` **DOES NOT PROMISE** that our code will run in parallel.  Each of our \"tasks\" will get a little bit of time to run, before it's expected to cede control back to the other tasks we're running.  But that's OK, because it'll cede control when it knows it'll have to wait a while before getting more communication.\n",
    "\n",
    "With `asyncio`, we know exactly when in a function's execution we might cede control to another task. By using local variables, we know that our task won't interfere with any other tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early `asyncio` was based on generators\n",
    "\n",
    "Behind the scenes, there are still some Python generators (and generator functions) hiding.  However, modern Python doesn't really use generators.\n",
    "\n",
    "That said, generators can really help us to understand what's happening in `asyncio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumbest function in the world\n",
    "\n",
    "def myfunc():\n",
    "    return 1\n",
    "    return 2\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc()  # we run it, and it gets to \"return 1\", returns 1, and that's the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2           0 LOAD_CONST               1 (1)\n",
      "              2 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "import dis\n",
    "dis.dis(myfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator function\n",
    "\n",
    "def mygen():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3\n",
    "    \n",
    "# yield means: give a value back and wait -- go to sleep    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object mygen at 0x1110cd230>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when you run a generator function, you get a generator object back\n",
    "# generator objects implement the iterator protocol\n",
    "\n",
    "mygen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# each time we ask for the next element from the generator (i.e., mygen()),\n",
    "# the generator function runs up to and including the next \"yield\".  \"yield\"\n",
    "# tells the generator function to return a value, and go to sleep, remembering\n",
    "# where it was!\n",
    "\n",
    "for one_item in mygen():\n",
    "    print(one_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_up_to: 0\n",
      "fib: 0\n",
      "squares: 0\n",
      "count_up_to: 1\n",
      "fib: 1\n",
      "squares: 1\n",
      "count_up_to: 2\n",
      "fib: 1\n",
      "squares: 4\n",
      "count_up_to: 3\n",
      "fib: 2\n",
      "squares: 9\n",
      "count_up_to: 4\n",
      "fib: 3\n",
      "squares: 16\n",
      "count_up_to: 5\n",
      "fib: 5\n",
      "squares: 25\n",
      "count_up_to: 6\n",
      "fib: 8\n",
      "squares: 36\n",
      "count_up_to: 7\n",
      "fib: 13\n",
      "squares: 49\n",
      "count_up_to: 8\n",
      "count_up_to: 9\n",
      "squares: 64\n",
      "squares: 81\n",
      "squares: 100\n"
     ]
    }
   ],
   "source": [
    "def count_up_to(maxnum):\n",
    "    for one_number in range(maxnum):\n",
    "        yield one_number\n",
    "        \n",
    "def fib(maxnum):\n",
    "    first = 0\n",
    "    second = 1\n",
    "    counter = 0\n",
    "    while True:\n",
    "        yield first\n",
    "        counter += 1\n",
    "        first, second = second, first+second\n",
    "        \n",
    "        if counter >= maxnum:\n",
    "            break\n",
    "            \n",
    "def squares(maxnum):\n",
    "    for one_number in range(maxnum):\n",
    "        yield one_number ** 2\n",
    "        \n",
    "g1 = count_up_to(10)        \n",
    "g2 = fib(8)\n",
    "g3 = squares(11)\n",
    "\n",
    "all_generators = [g1, g2, g3]\n",
    "\n",
    "while all_generators:\n",
    "    for one_generator in all_generators:\n",
    "        try:\n",
    "            value = next(one_generator)\n",
    "            print(f'{one_generator.__name__}: {value}')\n",
    "        except StopIteration:\n",
    "            all_generators.remove(one_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What did we just see?\n",
    "\n",
    "- Generator functions look like regular functions, but when you run them, you get *generator objects*.\n",
    "- A generator implements the iterator protocol, so we can use it in a `for` loop.\n",
    "- Each time we ask for the generator to run a little bit, it does so until it hits `yield`.  That's the signal to let someone else run; the generator goes to sleep, and will pick up where it left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic `asyncio` \n",
    "\n",
    "In `asyncio`, you don't your functions directly.  Rather, you put your function on the \"event loop,\" an infinite loop that goes through each function you've added, and gives it a chance to run until the function is done.\n",
    "\n",
    "- When we write a function for `asyncio`, it's called a \"coroutine function.\"  \n",
    "- When we run a coroutine function, we get back a \"coroutine object.\"\n",
    "\n",
    "How do we write a coroutine, vs. a regular function? We use the special syntax `async def` instead of `def`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function main at 0x1121c3c70>\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    print('Hello, world!')\n",
    "\n",
    "print(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object main at 0x112071b60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords\n",
    "\n",
    "- `async` before `def` means: We are defining a coroutine function\n",
    "- `await` can only be used inside of a coroutine function, and it means: I know that what I'm about to run is going to take a while to get back to me, so I'll wait here while it run and will continue when it returns\n",
    "\n",
    "You can only use `await` on values that are \"awaitable,\" meaning, they're designed to be used with `asyncio`.  The other thing to remember/realize is that `await` does cede control of the CPU to the loop, but it blocks in this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raymond Hettinger compares threading, processes, and asyncio: https://www.youtube.com/watch?v=9zinZmE3Ogk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We write coroutine functions.\n",
    "- When we execute coroutine functions, we get coroutine objects.\n",
    "- We can then ask `asyncio` to put our coroutine objects on the loop.\n",
    "- When we do that, our routine is known as a \"task.\"\n",
    "\n",
    "A task is a scheduled coroutine object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threads vs. `asyncio`, and operating systems\n",
    "\n",
    "With threads (and processes), our tasks are given an amount of time to run. When that time slice is up, the OS yanks control away from the thread/process.  That's why you can have race conditions, because you don't know when that might happen, or what you might be in the middle of.\n",
    "\n",
    "- Good news: No thread/process can gum up the system\n",
    "- Bad news: You end up with race conditions, etc.\n",
    "\n",
    "With `asyncio`, our tasks decide when they're good and ready to cede control with `await`.\n",
    "\n",
    "- Good news: This makes it easier to reason about things, and to ensure there aren't weird conditions\n",
    "- Bad news: A poorly behaved task (i.e., one without any `await` in it) can monopolize the CPU.\n",
    "\n",
    "Before modern versions of the Mac OS and Windows, those operating systems used \"cooperative multitasking\" â€” a program would tell the OS when it was ready to cede control of the CPU. Which meant that a badly behaved application could lock up your whole system. That's much harder to do nowadays with preemptive multitasking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next up\n",
    "\n",
    "- Practice this a bit\n",
    "- Getting task values back\n",
    "- Gathering groups of tsks\n",
    "- Starting to look at the loop explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return at :20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: ahello\n",
    "\n",
    "(More or less) copy what I've done in my `a03.py` file:\n",
    "\n",
    "- Define a `greet` coroutine that takes a string and a number of times to `print` that string\n",
    "- Define a `main` coroutine that creates two tasks based on `greet`, asking it to print two different strings, two different numbers of times\n",
    "- Run `main` via `asyncio.run`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# I'm going to write a second coroutine function\n",
    "\n",
    "\n",
    "async def greet(s, n):\n",
    "    for i in range(n):\n",
    "        # cede control of the CPU with await in your function\n",
    "        print(s)\n",
    "        await asyncio.sleep(0.1)   # go to sleep -- aka give up control\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # set up / schedule the tasks -- what do you want to run?\n",
    "    t1 = asyncio.create_task(greet('hello', 3))\n",
    "    t2 = asyncio.create_task(greet('goodbye', 4))\n",
    "\n",
    "    # wait for t1 and t2 to finish, then let main die\n",
    "    # if I use this, then main will exit after t1 and t2 are both done\n",
    "    await t1\n",
    "    await t2\n",
    "\n",
    "    # alternatively, we can sleep for a certain amount of time\n",
    "    # if I use this, then main will exit after 5 seconds, hopefully enough for t1+t2 to do their thing\n",
    "    # asyncio.sleep(5)\n",
    "\n",
    "\n",
    "# how do we run it? We put it on the event loop\n",
    "# I don't put main, the function, on the event loop\n",
    "# rather, I put main(), the result of calling main, on the loop\n",
    "# print('Before')\n",
    "# asyncio.run(main())\n",
    "# print('After')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "goodbye\n",
      "hello\n",
      "goodbye\n",
      "hello\n",
      "goodbye\n",
      "goodbye\n"
     ]
    }
   ],
   "source": [
    "# I can run things in Jupyter, because it *already* has an event loop running\n",
    "# But I *CANNOT* run things with asyncio.run, because that tries to then stop all tasks\n",
    "# on the loop, and I'll end up in trouble.\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminology\n",
    "\n",
    "- When we run a coroutine function, we get a coroutine object.\n",
    "- When we schedule a coroutine object, we get a *task* object.\n",
    "- A task is a subclass of \"Future\"\n",
    "\n",
    "Future objects basically say, \"I will eventually give you a result, whatever the function intended to return. When it's ready, I'll be able to provide that.\"\n",
    "\n",
    "We can then as a task object: Is it done running?   What was the value we got back?\n",
    "\n",
    "We can also put a bunch of tasks into a new future object, one that we can then query as a group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Summing and multiplying\n",
    "\n",
    "1. Define two coroutines, `sumto` and `factorial`. The `sumto` coroutine should sum all of the numbers up to its integer argument, and `factorial` should calculate factorial for its integer argument.\n",
    "2. Schedules tasks for both of these from within `main`, and then wait for both of them to finish.\n",
    "3. Print the results from these two coroutines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next up:\n",
    "\n",
    "1. Dig deeper into the event loop\n",
    "2. How do you use non-coroutines from within an asyncio program? (Answer: Threads!)\n",
    "3. HTTP client example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resume at :20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
